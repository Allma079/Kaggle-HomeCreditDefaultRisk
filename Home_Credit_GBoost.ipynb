{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading Data & Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T22:26:52.299907Z",
     "start_time": "2018-07-28T22:26:49.584026Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "### Notice: JUMP To Predict model to load csv file if this part has already been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:36.595258Z",
     "start_time": "2018-07-28T21:36:22.425520Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "application_test = pd.read_csv('data/application_test.csv')\n",
    "application_train = pd.read_csv('data/application_train.csv')\n",
    "bureau = pd.read_csv('data/bureau.csv')\n",
    "credit_card_balance = pd.read_csv(\"data/credit_card_balance.csv\")\n",
    "pcb = pd.read_csv(\"data/POS_CASH_balance.csv\")\n",
    "previous_application = pd.read_csv(\"data/previous_application.csv\")\n",
    "installments_payments = pd.read_csv(\"data/installments_payments.csv\")\n",
    "bureau_balance = pd.read_csv('data/bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:37.095980Z",
     "start_time": "2018-07-28T21:37:36.597273Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "application_test['TARGET'] = np.nan\n",
    "app = application_train.append(application_test, ignore_index=True)\n",
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T22:16:08.963972Z",
     "start_time": "2018-07-28T22:16:08.958928Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Big thanks to Will Koehrsen and his [kernel](https://www.kaggle.com/willkoehrsen/clean-manual-feature-engineering) for the features and aggregation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:38.838612Z",
     "start_time": "2018-07-28T21:37:38.787842Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def agg_numeric(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Groups and aggregates the numeric values in a child dataframe\n",
    "    by the parent variable.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the child dataframe to calculate the statistics on\n",
    "        parent_var (string): \n",
    "            the parent variable used for grouping and aggregating\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated by the `parent_var` for \n",
    "            all numeric columns. Each observation of the parent variable will have \n",
    "            one row in the dataframe with the parent variable as the index. \n",
    "            The columns are also renamed using the `df_name`. Columns with all duplicate\n",
    "            values are removed. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != parent_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns=col)\n",
    "\n",
    "    # Only want the numeric variables\n",
    "    parent_ids = df[parent_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(parent_var).agg(\n",
    "        ['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = []\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "\n",
    "    # Remove the columns with all redundant values\n",
    "    _, idx = np.unique(agg, axis=1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "\n",
    "    return agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:38.874907Z",
     "start_time": "2018-07-28T21:37:38.841058Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def agg_categorical(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregates the categorical features in a child dataframe\n",
    "    for each observation of the parent variable.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "\n",
    "    parent_var : string\n",
    "        The variable by which to group and aggregate the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "\n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with aggregated statistics for each observation of the parent_var\n",
    "        The columns are also renamed and columns with duplicate values are removed.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "\n",
    "    column_names = []\n",
    "\n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['sum', 'count', 'mean']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    categorical.columns = column_names\n",
    "\n",
    "    # Remove duplicate columns by values\n",
    "    _, idx = np.unique(categorical, axis=1, return_index=True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "\n",
    "    return categorical.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:38.894973Z",
     "start_time": "2018-07-28T21:37:38.877414Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def agg_child(df, parent_var, df_name):\n",
    "    \"\"\"Aggregate a child dataframe for each observation of the parent.\"\"\"\n",
    "\n",
    "    # Numeric and then categorical\n",
    "    df_agg = agg_numeric(df, parent_var, df_name)\n",
    "    df_agg_cat = agg_categorical(df, parent_var, df_name)\n",
    "\n",
    "    # Merge on the parent variable\n",
    "    df_info = df_agg.merge(df_agg_cat, on=parent_var, how='outer')\n",
    "\n",
    "    # Remove any columns with duplicate values\n",
    "    _, idx = np.unique(df_info, axis=1, return_index=True)\n",
    "    df_info = df_info.iloc[:, idx]\n",
    "\n",
    "    del df_agg, df_agg_cat\n",
    "\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:38.971448Z",
     "start_time": "2018-07-28T21:37:38.897616Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def agg_grandchild(df, parent_df, parent_var, grandparent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregate a grandchild dataframe at the grandparent level.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "        df : dataframe\n",
    "            Data with each row representing one observation\n",
    "\n",
    "        parent_df : dataframe\n",
    "            Parent table of df that must have the parent_var and \n",
    "            the grandparent_var. Used only to get the grandparent_var into\n",
    "            the dataframe after aggregations\n",
    "\n",
    "        parent_var : string\n",
    "            Variable representing each unique observation in the parent.\n",
    "            For example, `SK_ID_BUREAU` or `SK_ID_PREV`\n",
    "\n",
    "        grandparent_var : string\n",
    "            Variable representing each unique observation in the grandparent.\n",
    "            For example, `SK_ID_CURR`. \n",
    "\n",
    "        df_name : string\n",
    "            String for renaming the resulting columns.\n",
    "            The columns are name with the `df_name` and with the \n",
    "            statistic calculated in the column\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "        df_info : dataframe\n",
    "            A dataframe with one row for each observation of the grandparent variable.\n",
    "            The grandparent variable forms the index, and the resulting dataframe\n",
    "            can be merged with the grandparent to be used for training/testing. \n",
    "            Columns with all duplicate values are removed from the dataframe before returning.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # set the parent_var as the index of the parent_df for faster merges\n",
    "    parent_df = parent_df[[parent_var, grandparent_var]\n",
    "                          ].copy()  # .set_index(parent_var)\n",
    "\n",
    "    # Aggregate the numeric variables at the parent level\n",
    "    df_agg = agg_numeric(df, parent_var, '%s_LOAN' % df_name)\n",
    "\n",
    "    # Merge to get the grandparent variable in the data\n",
    "    df_agg = df_agg.merge(parent_df,\n",
    "                          on=parent_var, how='left')\n",
    "\n",
    "    # Aggregate the numeric variables at the grandparent level\n",
    "    df_agg_client = agg_numeric(df_agg, grandparent_var, '%s_CLIENT' % df_name)\n",
    "\n",
    "    # Can only apply one-hot encoding to categorical variables\n",
    "    if any(df.dtypes == 'object'):\n",
    "\n",
    "        # Aggregate the categorical variables at the parent level\n",
    "        df_agg_cat = agg_categorical(df, parent_var, '%s_LOAN' % df_name)\n",
    "        df_agg_cat = df_agg_cat.merge(parent_df,\n",
    "                                      on=parent_var, how='left')\n",
    "\n",
    "        # Aggregate the categorical variables at the grandparent level\n",
    "        df_agg_cat_client = agg_numeric(\n",
    "            df_agg_cat, grandparent_var, '%s_CLIENT' % df_name)\n",
    "        df_info = df_agg_client.merge(\n",
    "            df_agg_cat_client, on=grandparent_var, how='outer')\n",
    "\n",
    "        del df_agg, df_agg_client, df_agg_cat, df_agg_cat_client\n",
    "\n",
    "    # If there are no categorical variables, then we only need the numeric aggregations\n",
    "    else:\n",
    "        df_info = df_agg_client.copy()\n",
    "\n",
    "        del df_agg, df_agg_client\n",
    "\n",
    "    # Drop the columns with all duplicated values\n",
    "    _, idx = np.unique(df_info, axis=1, return_index=True)\n",
    "    df_info = df_info.iloc[:, idx]\n",
    "\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:38.749694Z",
     "start_time": "2018-07-28T21:37:37.098467Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "\n",
    "app['LOAN_RATE'] = app['AMT_ANNUITY'] / app['AMT_CREDIT']\n",
    "app['CREDIT_INCOME_RATIO'] = app['AMT_CREDIT'] / app['AMT_INCOME_TOTAL']\n",
    "app['EMPLOYED_BIRTH_RATIO'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "\n",
    "app['EXT_SOURCE_MULT_1'] = app['EXT_SOURCE_1']*app['EXT_SOURCE_2']\n",
    "app['EXT_SOURCE_MULT_2'] = app['EXT_SOURCE_1']*app['EXT_SOURCE_3']\n",
    "app['EXT_SOURCE_MULT_3'] = app['EXT_SOURCE_2']*app['EXT_SOURCE_3']\n",
    "app['EXT_SOURCE_MULT_4'] = app['EXT_SOURCE_1'] * \\\n",
    "    app['EXT_SOURCE_2']*app['EXT_SOURCE_3']\n",
    "\n",
    "app['EXT_SOURCE_COS_1'] = np.cos(app['EXT_SOURCE_1'])\n",
    "app['EXT_SOURCE_COS_2'] = np.cos(app['EXT_SOURCE_2'])\n",
    "app['EXT_SOURCE_COS_3'] = np.cos(app['EXT_SOURCE_3'])\n",
    "\n",
    "app['EXT_SOURCE_SIN_1'] = np.sin(app['EXT_SOURCE_1'])\n",
    "app['EXT_SOURCE_SIN_2'] = np.sin(app['EXT_SOURCE_2'])\n",
    "app['EXT_SOURCE_SIN_3'] = np.sin(app['EXT_SOURCE_3'])\n",
    "\n",
    "app['EXT_SOURCE_SUM'] = app[['EXT_SOURCE_1',\n",
    "                             'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
    "app['EXT_SOURCE_MEAN'] = app[['EXT_SOURCE_1',\n",
    "                              'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "app['AMT_REQ_SUM'] = app[[\n",
    "    x for x in app.columns if 'AMT_REQ_' in x]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app['app missing'] = app.isnull().sum(axis=1).values\n",
    "app['app EXT_SOURCE mean'] = app[['EXT_SOURCE_1',\n",
    "                                  'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "app['app EXT_SOURCE std'] = app[['EXT_SOURCE_1',\n",
    "                                 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "app['app EXT_SOURCE prod'] = app['EXT_SOURCE_1'] * \\\n",
    "    app['EXT_SOURCE_2'] * app['EXT_SOURCE_3']\n",
    "app['app EXT_SOURCE_1 * DAYS_EMPLOYED'] = app['EXT_SOURCE_1'] * app['DAYS_EMPLOYED']\n",
    "app['app EXT_SOURCE_2 * DAYS_EMPLOYED'] = app['EXT_SOURCE_2'] * app['DAYS_EMPLOYED']\n",
    "app['app EXT_SOURCE_3 * DAYS_EMPLOYED'] = app['EXT_SOURCE_3'] * app['DAYS_EMPLOYED']\n",
    "\n",
    "app['app EXT_SOURCE_1 / DAYS_BIRTH'] = app['EXT_SOURCE_1'] / app['DAYS_BIRTH']\n",
    "app['app EXT_SOURCE_2 / DAYS_BIRTH'] = app['EXT_SOURCE_2'] / app['DAYS_BIRTH']\n",
    "app['app EXT_SOURCE_3 / DAYS_BIRTH'] = app['EXT_SOURCE_3'] / app['DAYS_BIRTH']\n",
    "\n",
    "app['app AMT_CREDIT - AMT_GOODS_PRICE'] = app['AMT_CREDIT'] - app['AMT_GOODS_PRICE']\n",
    "app['app AMT_CREDIT / AMT_GOODS_PRICE'] = app['AMT_CREDIT'] / app['AMT_GOODS_PRICE']\n",
    "app['app AMT_CREDIT / AMT_ANNUITY'] = app['AMT_CREDIT'] / app['AMT_ANNUITY']\n",
    "app['app AMT_CREDIT / AMT_INCOME_TOTAL'] = app['AMT_CREDIT'] / \\\n",
    "    app['AMT_INCOME_TOTAL']\n",
    "\n",
    "app['app AMT_INCOME_TOTAL / 12 - AMT_ANNUITY'] = app['AMT_INCOME_TOTAL'] / \\\n",
    "    12. - app['AMT_ANNUITY']\n",
    "app['app AMT_INCOME_TOTAL / AMT_ANNUITY'] = app['AMT_INCOME_TOTAL'] / \\\n",
    "    app['AMT_ANNUITY']\n",
    "app['app AMT_INCOME_TOTAL - AMT_GOODS_PRICE'] = app['AMT_INCOME_TOTAL'] - \\\n",
    "    app['AMT_GOODS_PRICE']\n",
    "app['app AMT_INCOME_TOTAL / CNT_FAM_MEMBERS'] = app['AMT_INCOME_TOTAL'] / \\\n",
    "    app['CNT_FAM_MEMBERS']\n",
    "app['app AMT_INCOME_TOTAL / CNT_CHILDREN'] = app['AMT_INCOME_TOTAL'] / \\\n",
    "    (1 + app['CNT_CHILDREN'])\n",
    "\n",
    "app['app most popular AMT_GOODS_PRICE'] = app['AMT_GOODS_PRICE'].isin(\n",
    "    [225000, 450000, 675000, 900000]).map({True: 1, False: 0})\n",
    "app['app popular AMT_GOODS_PRICE'] = app['AMT_GOODS_PRICE'].isin(\n",
    "    [1125000, 1350000, 1575000, 1800000, 2250000]).map({True: 1, False: 0})\n",
    "app['app OWN_CAR_AGE / DAYS_BIRTH'] = app['OWN_CAR_AGE'] / app['DAYS_BIRTH']\n",
    "app['app OWN_CAR_AGE / DAYS_EMPLOYED'] = app['OWN_CAR_AGE'] / app['DAYS_EMPLOYED']\n",
    "\n",
    "app['app DAYS_LAST_PHONE_CHANGE / DAYS_BIRTH'] = app['DAYS_LAST_PHONE_CHANGE'] / \\\n",
    "    app['DAYS_BIRTH']\n",
    "app['app DAYS_LAST_PHONE_CHANGE / DAYS_EMPLOYED'] = app['DAYS_LAST_PHONE_CHANGE'] / \\\n",
    "    app['DAYS_EMPLOYED']\n",
    "app['app DAYS_EMPLOYED - DAYS_BIRTH'] = app['DAYS_EMPLOYED'] - app['DAYS_BIRTH']\n",
    "app['app DAYS_EMPLOYED / DAYS_BIRTH'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "app['app CNT_CHILDREN / CNT_FAM_MEMBERS'] = app['CNT_CHILDREN'] / \\\n",
    "    app['CNT_FAM_MEMBERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:38.989730Z",
     "start_time": "2018-07-28T21:37:38.973504Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "bureau['LOAN_RATE'] = bureau['AMT_ANNUITY'] / bureau['AMT_CREDIT_SUM']\n",
    "bureau['bureau AMT_CREDIT_SUM - AMT_CREDIT_SUM_DEBT'] = bureau['AMT_CREDIT_SUM'] - \\\n",
    "    bureau['AMT_CREDIT_SUM_DEBT']\n",
    "bureau['bureau AMT_CREDIT_SUM - AMT_CREDIT_SUM_LIMIT'] = bureau['AMT_CREDIT_SUM'] - \\\n",
    "    bureau['AMT_CREDIT_SUM_LIMIT']\n",
    "bureau['bureau AMT_CREDIT_SUM - AMT_CREDIT_SUM_OVERDUE'] = bureau['AMT_CREDIT_SUM'] - \\\n",
    "    bureau['AMT_CREDIT_SUM_OVERDUE']\n",
    "bureau['bureau DAYS_CREDIT - CREDIT_DAY_OVERDUE'] = bureau['DAYS_CREDIT'] - \\\n",
    "    bureau['CREDIT_DAY_OVERDUE']\n",
    "bureau['bureau DAYS_CREDIT - DAYS_CREDIT_ENDDATE'] = bureau['DAYS_CREDIT'] - \\\n",
    "    bureau['DAYS_CREDIT_ENDDATE']\n",
    "bureau['bureau DAYS_CREDIT - DAYS_ENDDATE_FACT'] = bureau['DAYS_CREDIT'] - \\\n",
    "    bureau['DAYS_ENDDATE_FACT']\n",
    "bureau['bureau DAYS_CREDIT_ENDDATE - DAYS_ENDDATE_FACT'] = bureau['DAYS_CREDIT_ENDDATE'] - \\\n",
    "    bureau['DAYS_ENDDATE_FACT']\n",
    "bureau['bureau DAYS_CREDIT_UPDATE - DAYS_CREDIT_ENDDATE'] = bureau['DAYS_CREDIT_UPDATE'] - \\\n",
    "    bureau['DAYS_CREDIT_ENDDATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:37:58.498722Z",
     "start_time": "2018-07-28T21:37:38.992928Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bureau_info = agg_child(bureau, 'SK_ID_CURR', 'BUREAU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:38:01.023059Z",
     "start_time": "2018-07-28T21:37:58.501168Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "bureau_balance['PAST_DUE'] = bureau_balance['STATUS'].isin(\n",
    "    ['1', '2', '3', '4', '5'])\n",
    "bureau_balance['ON_TIME'] = bureau_balance['STATUS'] == '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:38:01.029992Z",
     "start_time": "2018-07-28T21:38:01.024991Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:38:45.409310Z",
     "start_time": "2018-07-28T21:38:01.032961Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_balance_info = agg_grandchild(\n",
    "    bureau_balance, bureau, 'SK_ID_BUREAU', 'SK_ID_CURR', 'BB')\n",
    "del bureau_balance, bureau\n",
    "bureau_balance_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:38:45.420315Z",
     "start_time": "2018-07-28T21:38:45.413787Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_balance_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:38:56.525632Z",
     "start_time": "2018-07-28T21:38:45.422527Z"
    }
   },
   "outputs": [],
   "source": [
    "app = app.merge(bureau_info, on='SK_ID_CURR', how='left')\n",
    "del bureau_info\n",
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:39:10.773990Z",
     "start_time": "2018-07-28T21:38:56.527878Z"
    }
   },
   "outputs": [],
   "source": [
    "app = app.merge(bureau_balance_info, on='SK_ID_CURR', how='left')\n",
    "del bureau_balance_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:39:10.781328Z",
     "start_time": "2018-07-28T21:39:10.776583Z"
    }
   },
   "outputs": [],
   "source": [
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:39:10.896980Z",
     "start_time": "2018-07-28T21:39:10.784414Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "previous_application['LOAN_RATE'] = previous_application['AMT_ANNUITY'] / \\\n",
    "    previous_application['AMT_CREDIT']\n",
    "previous_application[\"AMT_DIFFERENCE\"] = previous_application['AMT_CREDIT'] - \\\n",
    "    previous_application['AMT_APPLICATION']\n",
    "\n",
    "previous_application['prev missing'] = previous_application.isnull().sum(\n",
    "    axis=1).values\n",
    "previous_application['prev AMT_APPLICATION - AMT_CREDIT'] = previous_application['AMT_APPLICATION'] - \\\n",
    "    previous_application['AMT_CREDIT']\n",
    "previous_application['prev AMT_APPLICATION - AMT_GOODS_PRICE'] = previous_application['AMT_APPLICATION'] - \\\n",
    "    previous_application['AMT_GOODS_PRICE']\n",
    "previous_application['prev AMT_GOODS_PRICE - AMT_CREDIT'] = previous_application['AMT_GOODS_PRICE'] - \\\n",
    "    previous_application['AMT_CREDIT']\n",
    "\n",
    "previous_application['prev DAYS_FIRST_DRAWING - DAYS_FIRST_DUE'] = previous_application['DAYS_FIRST_DRAWING'] - \\\n",
    "    previous_application['DAYS_FIRST_DUE']\n",
    "previous_application['prev DAYS_TERMINATION less -500'] = (\n",
    "    previous_application['DAYS_TERMINATION'] < -500).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:41:07.693245Z",
     "start_time": "2018-07-28T21:39:10.899443Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_info = agg_child(previous_application, 'SK_ID_CURR', 'PREVIOUS')\n",
    "previous_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:43:07.309637Z",
     "start_time": "2018-07-28T21:41:07.697722Z"
    }
   },
   "outputs": [],
   "source": [
    "app = app.merge(previous_info, on='SK_ID_CURR', how='left')\n",
    "del previous_info\n",
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:43:08.011915Z",
     "start_time": "2018-07-28T21:43:07.312036Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "installments_payments['LATE'] = installments_payments['DAYS_ENTRY_PAYMENT'] > installments_payments['DAYS_INSTALMENT']\n",
    "installments_payments['LOW_PAYMENT'] = installments_payments['AMT_PAYMENT'] < installments_payments['AMT_INSTALMENT']\n",
    "installments_payments['ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT'] = installments_payments['DAYS_ENTRY_PAYMENT'] - \\\n",
    "    installments_payments['DAYS_INSTALMENT']\n",
    "installments_payments['ins NUM_INSTALMENT_NUMBER_100'] = (\n",
    "    installments_payments['NUM_INSTALMENT_NUMBER'] == 100).astype(int)\n",
    "installments_payments['ins DAYS_INSTALMENT more NUM_INSTALMENT_NUMBER'] = (\n",
    "    installments_payments['DAYS_INSTALMENT'] > installments_payments['NUM_INSTALMENT_NUMBER'] * 50 / 3 - 11500 / 3).astype(int)\n",
    "installments_payments['ins AMT_INSTALMENT - AMT_PAYMENT'] = installments_payments['AMT_INSTALMENT'] - \\\n",
    "    installments_payments['AMT_PAYMENT']\n",
    "installments_payments['ins AMT_PAYMENT / AMT_INSTALMENT'] = installments_payments['AMT_PAYMENT'] / \\\n",
    "    installments_payments['AMT_INSTALMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:43:49.713917Z",
     "start_time": "2018-07-28T21:43:08.013856Z"
    }
   },
   "outputs": [],
   "source": [
    "installments_info = agg_grandchild(\n",
    "    installments_payments, previous_application, 'SK_ID_PREV', 'SK_ID_CURR', 'IN')\n",
    "del installments_payments\n",
    "installments_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:44:26.755498Z",
     "start_time": "2018-07-28T21:43:49.716209Z"
    }
   },
   "outputs": [],
   "source": [
    "app = app.merge(installments_info, on='SK_ID_CURR', how='left')\n",
    "del installments_info\n",
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:44:27.316605Z",
     "start_time": "2018-07-28T21:44:26.761758Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "pcb['LATE_PAYMENT'] = pcb['SK_DPD'] > 0.0\n",
    "pcb['INSTALLMENTS_PAID'] = pcb['CNT_INSTALMENT'] - pcb['CNT_INSTALMENT_FUTURE']\n",
    "pcb['pos CNT_INSTALMENT more CNT_INSTALMENT_FUTURE'] = (\n",
    "    pcb['CNT_INSTALMENT'] > pcb['CNT_INSTALMENT_FUTURE']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:45:39.544905Z",
     "start_time": "2018-07-28T21:44:27.318540Z"
    }
   },
   "outputs": [],
   "source": [
    "cash_info = agg_grandchild(pcb, previous_application,\n",
    "                           'SK_ID_PREV', 'SK_ID_CURR', 'CASH')\n",
    "del pcb\n",
    "cash_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:46:30.222672Z",
     "start_time": "2018-07-28T21:45:39.548663Z"
    }
   },
   "outputs": [],
   "source": [
    "app = app.merge(cash_info, on='SK_ID_CURR', how='left')\n",
    "del cash_info\n",
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:46:30.602498Z",
     "start_time": "2018-07-28T21:46:30.225934Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE features\n",
    "credit_card_balance['OVER_LIMIT'] = credit_card_balance['AMT_BALANCE'] > credit_card_balance['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "credit_card_balance['BALANCE_CLEARED'] = credit_card_balance['AMT_BALANCE'] == 0.0\n",
    "credit_card_balance['LOW_PAYMENT'] = credit_card_balance['AMT_PAYMENT_CURRENT'] < credit_card_balance['AMT_INST_MIN_REGULARITY']\n",
    "credit_card_balance['LATE'] = credit_card_balance['SK_DPD'] > 0.0\n",
    "credit_card_balance['card missing'] = credit_card_balance.isnull().sum(\n",
    "    axis=1).values\n",
    "credit_card_balance['card SK_DPD - MONTHS_BALANCE'] = credit_card_balance['SK_DPD'] - \\\n",
    "    credit_card_balance['MONTHS_BALANCE']\n",
    "credit_card_balance['card SK_DPD_DEF - MONTHS_BALANCE'] = credit_card_balance['SK_DPD_DEF'] - \\\n",
    "    credit_card_balance['MONTHS_BALANCE']\n",
    "credit_card_balance['card SK_DPD - SK_DPD_DEF'] = credit_card_balance['SK_DPD'] - \\\n",
    "    credit_card_balance['SK_DPD_DEF']\n",
    "credit_card_balance['card AMT_TOTAL_RECEIVABLE - AMT_RECIVABLE'] = credit_card_balance['AMT_TOTAL_RECEIVABLE'] - \\\n",
    "    credit_card_balance['AMT_RECIVABLE']\n",
    "credit_card_balance['card AMT_TOTAL_RECEIVABLE - AMT_RECEIVABLE_PRINCIPAL'] = credit_card_balance['AMT_TOTAL_RECEIVABLE'] - \\\n",
    "    credit_card_balance['AMT_RECEIVABLE_PRINCIPAL']\n",
    "credit_card_balance['card AMT_RECIVABLE - AMT_RECEIVABLE_PRINCIPAL'] = credit_card_balance['AMT_RECIVABLE'] - \\\n",
    "    credit_card_balance['AMT_RECEIVABLE_PRINCIPAL']\n",
    "credit_card_balance['card AMT_BALANCE - AMT_RECIVABLE'] = credit_card_balance['AMT_BALANCE'] - \\\n",
    "    credit_card_balance['AMT_RECIVABLE']\n",
    "credit_card_balance['card AMT_BALANCE - AMT_RECEIVABLE_PRINCIPAL'] = credit_card_balance['AMT_BALANCE'] - \\\n",
    "    credit_card_balance['AMT_RECEIVABLE_PRINCIPAL']\n",
    "credit_card_balance['card AMT_BALANCE - AMT_TOTAL_RECEIVABLE'] = credit_card_balance['AMT_BALANCE'] - \\\n",
    "    credit_card_balance['AMT_TOTAL_RECEIVABLE']\n",
    "credit_card_balance['card AMT_DRAWINGS_CURRENT - AMT_DRAWINGS_ATM_CURRENT'] = credit_card_balance['AMT_DRAWINGS_CURRENT'] - \\\n",
    "    credit_card_balance['AMT_DRAWINGS_ATM_CURRENT']\n",
    "credit_card_balance['card AMT_DRAWINGS_CURRENT - AMT_DRAWINGS_OTHER_CURRENT'] = credit_card_balance['AMT_DRAWINGS_CURRENT'] - \\\n",
    "    credit_card_balance['AMT_DRAWINGS_OTHER_CURRENT']\n",
    "credit_card_balance['card AMT_DRAWINGS_CURRENT - AMT_DRAWINGS_POS_CURRENT'] = credit_card_balance['AMT_DRAWINGS_CURRENT'] - \\\n",
    "    credit_card_balance['AMT_DRAWINGS_POS_CURRENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:46:57.324732Z",
     "start_time": "2018-07-28T21:46:30.605944Z"
    }
   },
   "outputs": [],
   "source": [
    "credit_info = agg_grandchild(\n",
    "    credit_card_balance, previous_application, 'SK_ID_PREV', 'SK_ID_CURR', 'CC')\n",
    "del credit_card_balance, previous_application\n",
    "credit_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:23.636505Z",
     "start_time": "2018-07-28T21:46:57.327074Z"
    }
   },
   "outputs": [],
   "source": [
    "app = app.merge(credit_info, on='SK_ID_CURR', how='left')\n",
    "del credit_info\n",
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "for col in app:\n",
    "    if app[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app[col])\n",
    "            # Transform both training and testing data\n",
    "            app[col] = le.transform(app[col])\n",
    "\n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "\n",
    "print('%d columns were label encoded.' % le_count)\n",
    "list(app.select_dtypes('object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.to_csv('data/full_features_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.set_index('SK_ID_CURR', inplace=True)\n",
    "app = pd.get_dummies(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:23.665446Z",
     "start_time": "2018-07-28T21:48:23.641619Z"
    }
   },
   "outputs": [],
   "source": [
    "print('After manual feature engineering, there are {} features.'.format(\n",
    "    app.shape[1] - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:48.882904Z",
     "start_time": "2018-07-28T21:48:48.841189Z"
    }
   },
   "outputs": [],
   "source": [
    "app.TARGET.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T22:05:46.416023Z",
     "start_time": "2018-07-28T22:05:24.219873Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = app[app['TARGET'].notnull()].copy(\n",
    "), app[app['TARGET'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:49.155478Z",
     "start_time": "2018-07-28T21:48:48.940788Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:49.166297Z",
     "start_time": "2018-07-28T21:48:49.157927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare submission file\n",
    "def submission(y_pred, name):\n",
    "    my_submission = pd.DataFrame(\n",
    "        {'SK_ID_CURR': app_test_align.SK_ID_CURR, 'TARGET': y_pred})\n",
    "    my_submission.to_csv(name, index=False)\n",
    "    files.download(name)\n",
    "    print('Done! :-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.1 ROC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:49.180593Z",
     "start_time": "2018-07-28T21:48:49.169315Z"
    }
   },
   "outputs": [],
   "source": [
    "def roc_plot(y_truth, y_pred):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, treshold = roc_curve(y_truth, y_pred)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='LR')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:49.187078Z",
     "start_time": "2018-07-28T21:48:49.183187Z"
    }
   },
   "outputs": [],
   "source": [
    "def roc_score(y_truth, y_pred):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc = roc_auc_score(y_truth, y_pred)\n",
    "    print('####AUC-SCORE### \\n{}'.format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T21:48:49.256943Z",
     "start_time": "2018-07-28T21:48:49.189389Z"
    }
   },
   "outputs": [],
   "source": [
    "def xg_boost_r(trainset, testset, importance, final):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    if (final == 1):\n",
    "        x_train = trainset.drop('TARGET', axis=1)\n",
    "        y_train = trainset['TARGET']\n",
    "        x_test = testset.drop('TARGET', axis=1)\n",
    "        y_test = testset['TARGET']\n",
    "        dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "    else:\n",
    "        data_input = trainset.drop('TARGET', axis=1)\n",
    "        data_output = trainset['TARGET']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            data_input, data_output, test_size=0.2, random_state=42)\n",
    "        dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "\n",
    "    # Best params after doing gridsearch\n",
    "    param = {  # 'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': 0.3,  # so called `eta` value\n",
    "        'max_depth': 4,\n",
    "        'min_child_weight': 5,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.6,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'n_estimators': 300,  # number of trees\n",
    "        'seed': 42, 'gamma': 0.4}\n",
    "\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    y_pred_xgb = bst.predict(dtest)\n",
    "\n",
    "    if (final == 1):\n",
    "        print('Time =', str(datetime.timedelta(seconds=time.time() - start)))\n",
    "        return y_pred_xgb\n",
    "\n",
    "    if (importance == 1):\n",
    "        xgb.plot_importance(bst, max_num_features=100, figsize=(20, 20))\n",
    "        plt.show()\n",
    "\n",
    "    print('####Accuracy### \\n{}'.format(np.mean(y_pred_xgb == y_test)))\n",
    "    roc_score(y_test, y_pred_xgb)\n",
    "    roc_plot(y_test, y_pred_xgb)\n",
    "\n",
    "    print('Time =', str(datetime.timedelta(seconds=time.time() - start)))\n",
    "    return y_pred_xgb, bst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T01:42:35.968423Z",
     "start_time": "2018-07-29T01:42:35.950981Z"
    }
   },
   "outputs": [],
   "source": [
    "random_hyp = {'is_unbalance': True,\n",
    "              'n_estimators': 2673,\n",
    "              'num_leaves': 77,\n",
    "              'learning_rate': 0.00764,\n",
    "              'min_child_samples': 460,\n",
    "              'boosting_type': 'goss',\n",
    "              'subsample_for_bin': 240000,\n",
    "              'reg_lambda': 0.20,\n",
    "              'reg_alpha': 0.88,\n",
    "              'subsample': 0.95,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'verbose': 200,\n",
    "              'objective': 'binary',\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data/CSV with full features\n",
    "### Notice: This step can only be done if the previous part of the notebook has already been run. If the dataset is still loaded in the variable app, this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T00:31:34.958628Z",
     "start_time": "2018-07-29T00:29:35.348535Z"
    }
   },
   "outputs": [],
   "source": [
    "app = pd.read_csv('data/full_features_v2.csv')\n",
    "app.set_index('SK_ID_CURR', inplace=True)\n",
    "#app.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are some categorical variables left we one-hot encode them.\n",
    "app = pd.get_dummies(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T00:33:40.202780Z",
     "start_time": "2018-07-29T00:33:20.644369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing whether there are still object type columns in our dataset.\n",
    "list(app.select_dtypes('object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T00:33:54.255619Z",
     "start_time": "2018-07-29T00:33:44.209936Z"
    }
   },
   "outputs": [],
   "source": [
    "# If this has already been done in the steps above you don't need to repeat that!\n",
    "# Split loaded data to train and test set.\n",
    "\n",
    "train, test = app[app['TARGET'].notnull()].copy(\n",
    "), app[app['TARGET'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train.columns == test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T00:34:17.102581Z",
     "start_time": "2018-07-29T00:34:17.077282Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T01:38:33.980844Z",
     "start_time": "2018-07-29T01:38:33.972045Z"
    }
   },
   "outputs": [],
   "source": [
    "train.TARGET.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LightGBM Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T00:35:12.234977Z",
     "start_time": "2018-07-29T00:35:03.577763Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lgb = lgb.Dataset(train.drop(columns='TARGET'), label=train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T02:21:44.654316Z",
     "start_time": "2018-07-29T01:42:45.193577Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "start = time.time()\n",
    "model = lgb.train(random_hyp, train_lgb)\n",
    "print('Time =', str(datetime.timedelta(seconds=time.time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T02:21:57.123313Z",
     "start_time": "2018-07-29T02:21:54.450511Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(model, max_num_features=100, figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T02:22:04.121654Z",
     "start_time": "2018-07-29T02:22:03.886324Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_model('./lgbm_bin.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T02:22:33.586234Z",
     "start_time": "2018-07-29T02:22:23.296349Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test.drop(columns='TARGET').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T02:22:45.990679Z",
     "start_time": "2018-07-29T02:22:45.751423Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'SK_ID_CURR': list(test.index),\n",
    "                           'TARGET': preds})\n",
    "submission.to_csv('submission_manual.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 XGBoost Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T00:40:18.483535Z",
     "start_time": "2018-07-29T00:40:18.422478Z"
    }
   },
   "outputs": [],
   "source": [
    "ypred = xg_boost_r(train, test, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'SK_ID_CURR': list(test.index),\n",
    "                           'TARGET': ypred})\n",
    "submission.to_csv('submission_manual_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
